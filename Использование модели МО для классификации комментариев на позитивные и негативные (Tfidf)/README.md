# Классификация комментариев на позитивные и негативные

## Цель проекта
Обучить модель машинного обучения для классификации комментариев интернет-магазина на токсичные и нетоксичные. Требуемое качество модели: F1-метрика не ниже 0.75.

---

## Описание данных
- **text** — текст комментария.
- **toxic** — целевой признак, где:
  - 1 — токсичный комментарий.
  - 0 — нетоксичный комментарий.

---

## Этапы работы
### 1. Загрузка и подготовка данных
- Данные загружены из файла `toxic_comments.csv`.
- Пропуски и дубликаты отсутствуют.
- Текстовые данные обработаны:
  - **Очистка**:
    - Удалены знаки препинания и спецсимволы.
    - Все слова приведены к нижнему регистру.
  - **Лемматизация**:
    - Слова приведены к их начальной форме с использованием библиотеки `nltk`.
  - **Разделение данных**:
    - Данные разделены на тренировочную и тестовую выборки в соотношении 75:25.
  - **Векторизация**:
    - Преобразование текстов в числовой вид выполнено с помощью метода Tfidf (TF-IDF).

---

### 2. Обучение моделей
#### Проверенные модели
1. **Logistic Regression (Логистическая регрессия)**:
   - Проведён подбор гиперпараметров:
     - Лучший результат: `C=100`, `random_state=42`.
   - F1-метрика на тестовой выборке: **0.77**.

2. **Random Forest (Случайный лес)**:
   - При увеличении количества деревьев до 200 F1-метрика составила 0.73, что ниже установленного порога.

3. **Gradient Boosting (Градиентный бустинг)**:
   - Модель показала F1-метрику 0.75, однако обучение заняло больше времени по сравнению с логистической регрессией.

#### Итоговая модель
Наилучший результат показала модель **Logistic Regression** с параметрами `C=100` и `random_state=42`. Она была выбрана в качестве финальной модели.

---

### 3. Выводы
1. **Этап подготовки данных**:
   - Комментарии очищены и преобразованы с использованием Tfidf-векторизации.
   - Данные разделены на тренировочную и тестовую выборки.

2. **Результаты обучения**:
   - Модель Logistic Regression достигла F1-метрики **0.77** на тестовой выборке, что превышает установленный порог **0.75**.

3. **Рекомендации**:
   - Внедрить модель Logistic Regression для автоматической модерации комментариев.
   - Регулярно обновлять данные для переобучения модели и повышения её качества.
   - Рассмотреть возможность применения более сложных моделей (например, нейронных сетей) при увеличении объёма данных.
